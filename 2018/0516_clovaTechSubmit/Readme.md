# 제 2회 clova extension submit

실사가 끝나고 정신이 조금 풀린 날, 오랜만에 네이버 컨퍼런스를 갔다.

캡스톤디자인 교과목에 대해 똑같은 질문을 여러번 응대하고 있어, 현재 이 질문들을 챗봇으로 응대하고 관련 자료를 효과적으로 관리하는 프로젝트를 진행하고 있다.  
(준비물 허용 / 불허용은 챗봇 베타 서비스로 테스트 중)  

더불어, 동아리에서 google cloud function 을 활용한 프로젝트를 개발하며 최근 Serverless 의 매력에 빠졌고, 이 Serverless 함수를 캡스톤디자인 교과목과도 연계시킬 수 있을지 궁금해졌다.

1) 문장형 질문에 보다 효율적인 답변을 주기위한 챗봇 개발지식 함양  
2) Naver에서 제공하는 Serverless function 서비스  

그래서 위의 두가지 목적으로 이 컨퍼런스에 참여했다.


## 세션1: Clova extension에서 Interaction Model 설계 및 제작 노하우 

사실 딥러닝에 대해 겉햝기로 공부하고 봉인한 사례가 있어 다시 복습한다고 생각하고 이 세션을 들었다.  
진행은 NLU 개발자로 활동하는 김용희 개발자님께서 수고해주셨다.
![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image1_1.jpeg?raw=true)

먼저 다뤘던 이야가는 NLU의 정의!  
Natural Language Understanding (자연어 이해), 말 그대로 **한국어, 영어와 같은 자연어를 이해하도록 만드는 데 필요한 개념**을 말한다고 한다. **고전적인 아키텍쳐**라고 말씀하셨던 건 그런 맥락에서 말씀하셨던 것 같다.  
**NLU의 필요한 이유**! 컴퓨터는 모두가 알다시피 0과 1로 표현할 수 있는 **이진수** 체계..  
우리가 request를 제대로 정형화된 form으로 주어야 조회가 가능하기 때문에 질문도 위와 같이 NLU 개념을 활용하여 적절한 form을 만들어 보내주어야 하는 것이다..  
  
Clova는 NLU를 아래와 같이 진행한다.
- 일종의 목표(extension)가 정해지면  
- 목표와 관련하여 "사용자가 물어볼만한 질문과, 그 답변 자료" 를 마련하고  
- intent와 slot을 활용하여 질문 템플릿(Interaction Model)을 설계한 후 (정형화)   
- 사용자의 요청이 올 시, 질문 템플릿에 맞추어 서비스 제공에 필요한 포맷(JSON)으로 변경하여 질문에 응대
  
![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image1_2.png?raw=true) 
두서 없이 써보았는데, 위 사진을 보면 이해할 수 있을 것이다.   
결론은 Clova에서도 일종의 NLU 처리 과정을 위해 이런 과정을 만들고 기술적으로 구현했다는 것을 알 수 있었다. 
  
NLU 문제에서는 intent와 slot이 주 이슈라고 한다. 위에서 해당 설명이 빠졌는데 이야기하면 아래와 같다.  
> intent : 서술어 + 목적어를 표현하는 의미 카테고리 (동사형 요소)  
> slot   : 고유 명사, 이름, 날짜 / 숫자 등 DM에 필요한 유용한 정보 (명사형 요소)  
>   
> **상세 설명**은 아래 그림 참조
> ![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image1_3.png?raw=true)

인간 언어의 경외심을 느끼며 그 다음 이야기들을 들었던 것 같다.
1) 한가지 목표는 다양한 말로 표현이 가능하기 때문에, categorial information 통해 관리할 필요성이 있다.
> ex> 소리 키우기 : 볼륨업, 소리높여줘, 소리 크기좀 키워줘 ....
2) 가설을 세워 점수를 체킹하고 가중치 점수를 줌으로써 정답에 가까워질 수 있도록 지도한다.  
3) slot은 prediction 단위로 기본적으로 추출하며 (문자 단위(한국어), word 단위로(영어)), 단서로 삼는 정보는 prediction 대상 전후 n개의 문자열을 더 읽어 문장이 유사 또는 자연스러운지 확인하는 단계로 추출한다. 물론 훈련용 말뭉치들을 저장해두어야 가능하다.
4) 형태소 분석 정보(EOMI)를 보충하여, 동사/명사가 조사/어미 보다 중요하다는 것을 스스로 깨닫지는 못하겠지만 동음이의어 분간, 동사/형용사 원형을 추출할 수 있도록 도와준다. (아래 예 참고)  
  > 볼륨 올려 : 볼륨(slot) + 올리(intent) + **어(EOMI)**  
  > 볼륨 올리세요 : 볼륨(slot) + 올리(intent) + **세요(EOMI)**  
5) 제공된 카테고리와 무관한 문장은 어떤 카테고리로 분류될지 예측이 불가하다. 이 단점을 극복하기 위해 invocation name을 불렀을 때만 CEK를 실행하여 서비스 범위 밖 돌발 질문을 적게 한다. (UX적으로는 별로인 것 같지만 획기적인 아이디어)

5번을 이해하는 데는 좀 더 시간이 걸릴 것 같다. 굳이 이름 불러서 할 필요 없이 event를 기다리도록 설계해도 될 것 같은데 이 것이 어떻게 기술의 한계를 극복한 것인지 이해가 잘 되지 않았다. 다음에 기회가 된다면 여쭈어보고 싶다.

이런 경외(?)의 과정을 거치고 NLU 잘만들기 위한 노하우 공유의 시간을 가졌다.
먼저 이야기 나온 내용은 아래의 내용이다. 
> 1. 말뭉치 잘 만들기
> -> 훈련용 문장을 정성들여 잘 만들기
> -> intent 발화별 예시 잘 만들기
> 2. 사용자 발화 문장 많이 써내기
> 3. 표현 문장 다양화 하기

세부적으로 들어가면  
1. 양질 둘다 중요하지만 양보다는 질! 아래 이미지를 보면 이해가 잘 될 것이다.  
![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image1_4.jpeg?raw=true)
2. 의미/형태가 거의 같은 문장이 들어가지 않도록 한다
> ex> 20초만큼 앞으로 가줘(빨리감기 의도) / 5분 앞으로 가줘(되감기 의도)
3. slot range와 name을 정하는 기준이 일관되어야 한다.
> ex> <device>에어컨<device> 꺼줘 / <target>에어컨<target> 상태 알려줘
4. 어쩔 수 없는 경우 고난도 변별력 기르기 문제를 많이 포함한다.
> <movie>클래식<movie> OST 틀어줘 / <genre>클래식<genre> 틀어줘

그리고 Unseen slot 에 대해 다뤘는데 정의는 아래와 같다.
> Slot DB에 등장한 적 없는 slot
거꾸로 오르는 저힘찬 연어 (이름이 기억도 안난다.) 같은 노래 틀을 시 최선의 동의어/유의어만 추가시키는 게 이상적이고, 심부름 문장을 대표값으로 둘 수도 없는 것이고, 작은 slot DB일때는 Unseen slot을 최소화하는 것을 추천하는 바이고..!

위의 내용을 듣고 과거 Watson을 활용하여 개발했던 기억이 났다.  
예전에 캡스톤디자인 준비물 데이터를 넣을 때 경우의 수가 너무 다양하여 일부는 default 흐름으로 응대할 수 있도록 만들었었다.  
이 과정이 내 나름의 unseen slot 에 대한 대처였구나라는 걸 생각해봤다.

마지막 언급내용은 이랬다
> 기계학습 특성 및 원리를 이해하고 고려하면 더 좋은 데이터 제작이 가능하다.  
> 단서들이 나타나는 밸런스가 중요하다. 중요하지 않은 단어를 중요하게 인식하지 않도록 한다.  
> 초기 데이터를 입력 후 다양한 테스트 문장을 입력해보며 문장을 테스트하고, 분석이 안되는 문장을 위주로 꾸준히 추가한다.
뜬금 없지만 인간을 이기기에는 기계는 아직 부족하구나라는 자긍심(?)을 가져본다.

이 세션을 통해 watson 에 단어를 추가해주었던 작업들이 무슨 과정이었는지 이해되었다. 그리고 그때는 이해가 안됬던 내용들이 이해되고, 독립된 개념들이 서로 이어지는 것 같은 느낌을 받았다. 

이 내용들과 노하우를 기반으로 캡스톤디자인 챗봇이 문장형에도 대응할 수 있도록 완성시켜봐야겠다.

## 세션2: Clova extension 대화모델 엔진 구조와 Chatbot 개발 최적화 방안 

![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image2_1.jpeg?raw=true)

어찌보면 개발자가 집중해서 들어야 하는 강의였는데, 그러지 못했다 ㅠㅠ
전체적인 대화모델 엔진 구조와 절차, 알고리즘을 순차적으로 들었는데 결론을 먼저 이야기해보면 clova에서도 정말 많은 고민을 통해 엔진을 만들어냈고 우리는 그 기술을 활용만 할 뿐이라는 것을 알았다.

챗봇 framework의 전체적인 flow는
> 쿼리가 들어오면   
> **언어특징 추출 라이브러리**를 통해 형태소를 분석하고  
> **전처리 라이브러리**를 통해 분석된 언어를 대화 모델에 이해 가능한 형태로 변경하고  
> **쿼리분류기**를 통해 대화인지 아닌지 판정하고
> 챗봇 모델에 따른 답변을 생성하여 질의자에게 답변하는 과정을 거친다.  

그리고 당연한 이야기지만 지속적인 Feature 및 모델 개선, 추가에 보다 능동적으로 대응할 수 있도록 설계되었다고 한다. AI 및 챗봇 초보자에게는 이 내용도 감동이었다.  

CEK를 통해 챗봇을 보다 쉽게 만들 수 있게 해주고  
LSTM 을 통해 과거/새로운 정보를 받아 이전정보를 관리하고, 좋은 정보를 추출하는 과정을 통해 챗봇의 트레이닝을 도와주고
N-hot vector을 통해 조사가 특히 발전되어있는 한국에 맞추어 토큰 단위로 정보를 넣고 형태소, 어미/태그 등에 대한 내용도 넣어 성능을 높이는 등 
  
역시 블록체인과 마찬가지로  
머신러닝과 AI 또한 다양한 기술과 알고리즘이 접합되어 만들어진 기술이다.  
역시 신기술이란..!

그리고 앞에서 나왔던 "꾸준한 트레이닝과, 많은 양의 질 좋은 정보가 필요하다." 라는 이야기와 BaseLine Model 을 적극 활용해보라는 이야기..  
왜 tensorflow를 포함한 머신러닝 기술이 파이썬을 주로 활용하는지 다시 한 번 알게 되는 시간이었다.
  
역시 대세는 정보싸움..!

## 세션3: Serverless로 만드는 쉽고 효율적인 Clova extension

![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image3_1.jpeg?raw=true)

최근 구글 클라우드 function 을 사용하면서 관심을 갖게 된 Serverless!
앞서 오승현 강연자분께서 설명을 굉장히 잘해주셨다. 그분의 이야기를 좀 풀어보면
> serverless란 함수단위 동작으로 추상화 되어 서비스를 제공하는 것 (마치 서버가 없는 것처럼 느끼는 것)
> event는 모든 하나의 행위가 event 그 자체 (이 자리에서 발표하는 것, 듣는 것 등등)

serverless에 대한 정의를 귀에 잘 박히게 설명해주었다. 위의 정의 한 마디로 이 세션에서 얻을 최소 이득은 다 얻었다.  
그리고 함수를 호출할때마다 돈을 과금하는 형태이기 때문에, 사용하지 않을때도 돈을 지불하는 기존 이벤트 대기방식에 비해 효율적이라는 설명을 들었다.  
하긴.. 함수를 사용할 시에만 지불하는 프로세스이니 소비적 측면에서도 큰 이득이다. 더불어 실제 node.js의 express 구축이나 라우팅 처리도 필요가 없을 것이고, 스프링에서 극혐인 초기 설정... (지금은 springboot라는 사기캐릭이 있다고 하지만) 을 생각해보면, 서버를 모르는 사람들도 쉽게 접할 수 있을 것이라 생각한다. 
![image](https://github.com/ridickle7/LeeSangWoo_Reference/blob/master/2018/0516_clovaTechSubmit/0.imageRef/image3_3.jpeg?raw=true)

사실 이 세션에서 물어보고 싶은 게 좀 있었다. 
> 구글 클라우드 서비스와 같이 로컬로 받아와 디버깅을 할 수 있느냐
> javascript의 경우 이벤트 자체나 콜백데이터 자체를 파라미터로 받거나, 특정 이벤트에만 반응하여 이 함수가 실행되는 경우도 있을텐데 (ex> DB값 업데이트 되면 해당 함수가 실행) 이런 경우에는 라인 디버깅이 필요하다. 오로지 console만 통하여 확인해야 될까?

사실 2번 질문은 구글 클라우드 function 의 문제이기도 하다. 실제 google realtime database 연동하여 프로젝트를 진행하다가 저 사례때문에 오로지 console만을 통해 해당 코드를 개선할 수 있었기 때문이다.  
사실 2번 상황 자체가 특수한 상황이기도 하거니와, 구글과 네이버 등의 기술력이라면 충분히 고쳐질 것이라 생각하기 때문에..! 만약 clova 에서 해당 기능이 제공되지 않는다면 시간이 지난 뒤를 기대해본다.


## 세션4: 코오롱베니트의 Clova extension 계정연동 및 IoT 개발 경험 
는 저녁 일정으로 듣지 못했다.. 

## 총평
##### IT 개발자로 나아가기 위해 공부하고 배워나갈 것들이 많다.
아직도 부족하다는 걸 많이 느낀다. 최근 그런 생각이 많이 들어 신기술과 새로운 프로젝트도 참여하고 있는데, 아직도 나아갈 길이 멀었다는 것을 느꼈다. 직접 AI 구현까지는 힘들더라도 최소 캡스톤디자인 챗봇을 성공적으로 런칭하면서 해당 신기술에 대한 갈증을 풀고 싶다.

##### 기초 공부를 빡세게 해야겠다.
블록체인을 공부할때도 느꼈지만, AI와 머신러닝 역시 기본 컴퓨터 과학 지식이 수반되어야 하는 기술이라는 것을 알 수 있었다. 기초적인 알고리즘은 물론이고 클라우드, 운영체제 지식 등 CS 기본 지식을 놓지 않아야 한다는 생각을 오늘도 해본다.

##### AI와 머신러닝은 앞으로도 성장할 사업이고 기초지식은 알아야 한다.
망할 산업이 절대 아니다. 그러니까 많은 서비스들이 나왔고 지금도 AI와 머신러닝을 외치고 있는거겠지..! 망할 산업이 아니라는 것은 그거에 대해 이야기는 할 줄 알아야 된다는 것이고, 이름만 들어봤습니다라고 하면 반드시 개발자로서 도태될 것이다. 1번 내용과 연관되지만 챗봇을 런칭하면서 이 신기술에 대한 경험과 갈증을 풀어나가야겠다.

##### 네이버 감사합니다.
당연한 이야기지만 멀어도 찾아오게 되는 게 네이버 세션 강의이다. 위의 궁금했던 내용들은 이 세션들을 통해 어느정도 답을 얻었고 남은 건 이제 내 열정과 개발이라고 생각된다. 이렇게 마무리 글을 남기며 오늘도 intelliJ와 visual studio code를 같이 켜본다.
